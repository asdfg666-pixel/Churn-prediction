{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o59Wc08qrJpA",
        "outputId": "278623a4-9d41-498a-db79-a1defbb13b9e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.1.4)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.5)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.1)\n",
            "Collecting slicer==0.0.8 (from shap)\n",
            "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
            "Downloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (540 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.1/540.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.46.0 slicer-0.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePGqq84VrH-Y",
        "outputId": "686b1942-760c-4073-9c26-1fd1bc88005a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline(steps=[('preprocessor',\n",
            "                 ColumnTransformer(transformers=[('num',\n",
            "                                                  Pipeline(steps=[('imputer',\n",
            "                                                                   SimpleImputer()),\n",
            "                                                                  ('scaler',\n",
            "                                                                   StandardScaler())]),\n",
            "                                                  ['age', 'tenure']),\n",
            "                                                 ('cat',\n",
            "                                                  Pipeline(steps=[('imputer',\n",
            "                                                                   SimpleImputer(fill_value='missing',\n",
            "                                                                                 strategy='constant')),\n",
            "                                                                  ('onehot',\n",
            "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
            "                                                  ['gender', 'partner'])])),\n",
            "                ('classifier', RandomForestClassifier(random_state=42))])\n"
          ]
        }
      ],
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.base import clone\n",
        "\n",
        "def create_churn_prediction_pipeline(df):\n",
        "    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "    if 'churn' in numeric_features:\n",
        "        numeric_features.remove('churn')\n",
        "    if 'churn' in categorical_features:\n",
        "        categorical_features.remove('churn')\n",
        "\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))  # 'ignore' is crucial here\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', classifier)\n",
        "    ])\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "\n",
        "def train_model_and_compute_shap(pipeline, df):\n",
        "    X = df.drop('churn', axis=1)\n",
        "    y = df['churn']\n",
        "\n",
        "    pipeline.fit(X, y)\n",
        "\n",
        "    X_preprocessed = pipeline.named_steps['preprocessor'].transform(X)\n",
        "    model = pipeline.named_steps['classifier']\n",
        "\n",
        "    explainer = shap.TreeExplainer(model)\n",
        "    shap_values = explainer.shap_values(X_preprocessed)\n",
        "\n",
        "    return pipeline, explainer, shap_values, X_preprocessed\n",
        "\n",
        "\n",
        "def update_pipeline_for_dominant_features(pipeline, dominant_features):\n",
        "    preprocessor = pipeline.named_steps['preprocessor']\n",
        "\n",
        "    numeric_features = [f for f in preprocessor.transformers[0][2] if f in dominant_features]\n",
        "    categorical_features = [f for f in preprocessor.transformers[1][2] if f in dominant_features]\n",
        "\n",
        "    new_pipeline = clone(pipeline)\n",
        "\n",
        "    # Clone the transformers\n",
        "    new_numeric_transformer = clone(new_pipeline.named_steps['preprocessor'].transformers[0][1])\n",
        "    new_categorical_transformer = clone(new_pipeline.named_steps['preprocessor'].transformers[1][1])\n",
        "\n",
        "    new_preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', new_numeric_transformer, numeric_features),\n",
        "            ('cat', new_categorical_transformer, categorical_features)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    new_pipeline.named_steps['preprocessor'] = new_preprocessor\n",
        "    return new_pipeline\n",
        "\n",
        "\n",
        "\n",
        "def get_dominant_features(shap_values, X_preprocessed, feature_names, top_n=5):\n",
        "    mean_abs_shap = np.mean(np.abs(shap_values[1]), axis=0)\n",
        "    if len(feature_names) != len(mean_abs_shap):\n",
        "      if len(feature_names) < len(mean_abs_shap):\n",
        "        # If feature names are shorter, truncate mean_abs_shap\n",
        "        mean_abs_shap = mean_abs_shap[:len(feature_names)]\n",
        "      else:\n",
        "        # If mean_abs_shap is shorter, truncate feature_names\n",
        "        feature_names = feature_names[:len(mean_abs_shap)]\n",
        "\n",
        "    shap_importance = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'mean_abs_shap': mean_abs_shap\n",
        "    })\n",
        "\n",
        "    shap_importance = shap_importance.sort_values(by='mean_abs_shap', ascending=False)\n",
        "\n",
        "    dominant_features = shap_importance.head(top_n)['feature'].tolist()\n",
        "\n",
        "    return dominant_features\n",
        "\n",
        "# Sample Data (Replace with your actual data)\n",
        "data1 = pd.DataFrame({\n",
        "    'age': [25, 30, 35, 40],\n",
        "    'tenure': [2, 5, 8, 10],\n",
        "    'gender': ['Male', 'Female', 'Male', 'Female'],\n",
        "    'partner': ['Yes', 'No', 'Yes', 'Yes'],\n",
        "    'churn': [True, False, True, False]\n",
        "})\n",
        "\n",
        "pipeline = create_churn_prediction_pipeline(data1)  # Create the pipeline\n",
        "\n",
        "pipeline, explainer, shap_values, X_preprocessed = train_model_and_compute_shap(pipeline, data1)\n",
        "\n",
        "feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
        "\n",
        "dominant_features = get_dominant_features(shap_values, X_preprocessed, feature_names, top_n=2)\n",
        "updated_pipeline = update_pipeline_for_dominant_features(pipeline, dominant_features)\n",
        "\n",
        "print(updated_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "updated_pipeline.fit(data1.drop('churn', axis=1), data1['churn'])\n",
        "\n",
        "new_user = pd.DataFrame({\n",
        "    'age': [32],\n",
        "    'tenure': [3],\n",
        "    'gender': ['Female'],\n",
        "    'partner': ['No']\n",
        "})\n",
        "\n",
        "prediction = updated_pipeline.predict(new_user)\n",
        "if prediction[0] == 1:\n",
        "    print(\"The new user is likely to churn.\")\n",
        "else:\n",
        "    print(\"The new user is likely to stay.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUzpRdEirRzK",
        "outputId": "25e551bf-2593-48f1-d251-92ab71730d46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The new user is likely to stay.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gx37KGcqshri"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}